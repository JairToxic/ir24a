{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1: Importar Librerías\n"
      ],
      "metadata": {
        "id": "pcz7Fqs2isgP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exSuLD4rh8-u",
        "outputId": "f40150f3-a1ab-496b-dbf6-67e369ac80ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Importar bibliotecas necesarias para el manejo de datos, procesamiento de texto y aprendizaje automático\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Descargar recursos adicionales de NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 2: Cargar el Dataset"
      ],
      "metadata": {
        "id": "emYkF0WXiqSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al archivo ZIP que contiene el CSV\n",
        "ruta_al_zip = 'archive.zip'  # Asegúrate de que el archivo ZIP esté en el mismo directorio que este notebook\n",
        "\n",
        "# Nombre del archivo CSV dentro del ZIP\n",
        "nombre_archivo_csv = 'podcastdata_dataset.csv'\n",
        "\n",
        "# Extraer el archivo CSV del ZIP\n",
        "with zipfile.ZipFile(ruta_al_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall('../')  # Puedes especificar la ruta donde quieres extraer los archivos\n",
        "\n",
        "# Cargar el CSV en un DataFrame de pandas\n",
        "ruta_al_csv_extraido = '../' + nombre_archivo_csv\n",
        "dataset = pd.read_csv(ruta_al_csv_extraido)\n"
      ],
      "metadata": {
        "id": "2Np8-jC5imtI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3: Preprocesamiento de Texto"
      ],
      "metadata": {
        "id": "vk0S-MOxi07v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para preprocesar el texto\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Aplicar preprocesamiento al dataset\n",
        "dataset['texto_preprocesado'] = dataset['text'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "OgwJrw_4i4MT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4: Representación del Espacio Vectorial - TF-IDF\n"
      ],
      "metadata": {
        "id": "w3rrm9r8jLi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear la matriz TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['texto_preprocesado'])\n"
      ],
      "metadata": {
        "id": "5SJigKoAjNaJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 5: Representación del Espacio Vectorial - BERT\n"
      ],
      "metadata": {
        "id": "wXET2GWqjQAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el tokenizador y el modelo BERT preentrenado\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Función para obtener embeddings BERT de un solo texto\n",
        "def get_bert_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "    return cls_embedding\n",
        "\n",
        "# Función para obtener embeddings BERT de forma paralela\n",
        "def get_bert_embeddings_parallel(texts):\n",
        "    embeddings = []\n",
        "    with ThreadPoolExecutor(max_workers=None) as executor:\n",
        "        for embedding in executor.map(get_bert_embeddings, texts):\n",
        "            embeddings.append(embedding)\n",
        "    return torch.cat([torch.tensor(embedding.numpy()) for embedding in embeddings], dim=0)\n",
        "\n",
        "# Obtener embeddings BERT para cada transcripción preprocesada en el dataset de forma paralela\n",
        "bert_embeddings = get_bert_embeddings_parallel(dataset['texto_preprocesado'])\n",
        "\n",
        "# Mostrar la forma de los embeddings\n",
        "print(f'Forma de los embeddings BERT: {bert_embeddings.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxZ5bXeejQqZ",
        "outputId": "17bf37d5-1398-4b8e-b3ea-20c89d44794f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de los embeddings BERT: torch.Size([319, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 6: Procesamiento de Consulta\n"
      ],
      "metadata": {
        "id": "7VhWbYSkjUUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para procesar consultas y calcular similitud utilizando TF-IDF y BERT\n",
        "def procesar_consulta(query, tfidf_matrix, bert_embeddings, dataset):\n",
        "    # Calcular similitud utilizando TF-IDF\n",
        "    tfidf_scores = tfidf_matrix @ tfidf_vectorizer.transform([query]).T\n",
        "\n",
        "    # Calcular embeddings BERT para la consulta\n",
        "    query_embedding = get_bert_embeddings(preprocess_text(query))\n",
        "\n",
        "    # Calcular similitud utilizando BERT\n",
        "    bert_scores = torch.cosine_similarity(query_embedding, bert_embeddings, dim=1)\n",
        "\n",
        "    # Obtener índices ordenados por similitud descendente para TF-IDF y BERT\n",
        "    tfidf_indices = tfidf_scores.toarray().flatten().argsort()[::-1]\n",
        "    bert_indices = bert_scores.argsort(descending=True)\n",
        "\n",
        "    # Obtener títulos de episodios basados en los índices ordenados\n",
        "    tfidf_results = dataset.iloc[tfidf_indices]['title']\n",
        "    bert_results = dataset.iloc[bert_indices]['title']\n",
        "\n",
        "    return tfidf_results, bert_results\n"
      ],
      "metadata": {
        "id": "gBHJ_AnWjUwx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 7: Recuperar y Comparar Resultados\n"
      ],
      "metadata": {
        "id": "1k4PKTHyjWXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para recuperar los resultados superiores basados en la similitud\n",
        "def retrieve_results(query, tfidf_matrix, bert_embeddings, dataset):\n",
        "    tfidf_results, bert_results = procesar_consulta(query, tfidf_matrix, bert_embeddings, dataset)\n",
        "\n",
        "    print(\"Resultados de TF-IDF:\")\n",
        "    print(tfidf_results.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "    print(\"\\nResultados de BERT:\")\n",
        "    print(bert_results.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "# Probar el sistema con una consulta de ejemplo\n",
        "query = \"Duncan\"\n",
        "retrieve_results(query, tfidf_matrix, bert_embeddings, dataset)\n"
      ],
      "metadata": {
        "id": "_fKM02ODjYOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30ffa9e-4386-40b8-934f-91c73b7a83ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de TF-IDF:\n",
            "126    Conversations, Ideas, Love, Freedom & The Joe ...\n",
            "305    Comedy, Sentient Robots, Suffering, Love & Bur...\n",
            "122    Origin of Life, Humans, Ideas, Suffering, and ...\n",
            "163    Sleep, Dreams, Creativity & the Limits of the ...\n",
            "170                                              Bitcoin\n",
            "102                      Artificial General Intelligence\n",
            "103               Computer Architecture and Data Storage\n",
            "104                                   Edison of Medicine\n",
            "105         Neuroscience, Psychology, and AI at DeepMind\n",
            "106                 Suffering in Humans, Animals, and AI\n",
            "Name: title, dtype: object\n",
            "\n",
            "Resultados de BERT:\n",
            "296                   Marxism, Capitalism, and Economics\n",
            "302    Doom, Quake, VR, AGI, Programming, Video Games...\n",
            "137           Ayn Rand and the Philosophy of Objectivism\n",
            "168           Solving Martial Arts from First Principles\n",
            "284                                      Imagine Dragons\n",
            "219    Cyc and the Quest to Solve Common Sense Reason...\n",
            "272                             Legendary Music Producer\n",
            "268    Space Colonization and Self-Assembling Space M...\n",
            "162    Difficult Conversations, Freedom of Speech, an...\n",
            "177                  Ayn Rand, Human Nature, and Anarchy\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 8: Probar el Sistema de IR\n"
      ],
      "metadata": {
        "id": "1WUgtwE-jZyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta de ejemplo para probar el sistema\n",
        "query = \"Artificial Intelligence\"\n",
        "\n",
        "# Recuperar y mostrar los resultados superiores utilizando TF-IDF y BERT\n",
        "retrieve_results(query, tfidf_matrix, bert_embeddings, dataset)\n"
      ],
      "metadata": {
        "id": "f-60aycvjbUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1716ac91-2386-4895-d9c5-fce5bf274e2e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de TF-IDF:\n",
            "2                                AI in the Age of Reason\n",
            "61      Concepts, Analogies, Common Sense & Future of AI\n",
            "119                             Measures of Intelligence\n",
            "38          Keras, Deep Learning, and the Progress of AI\n",
            "295    IQ Tests, Human Intelligence, and Group Differ...\n",
            "12                           Brains, Minds, and Machines\n",
            "0                                               Life 3.0\n",
            "91     Square, Cryptocurrency, and Artificial Intelli...\n",
            "1                                          Consciousness\n",
            "75      Universal Artificial Intelligence, AIXI, and AGI\n",
            "Name: title, dtype: object\n",
            "\n",
            "Resultados de BERT:\n",
            "296                   Marxism, Capitalism, and Economics\n",
            "168           Solving Martial Arts from First Principles\n",
            "3                                          Deep Learning\n",
            "223    Neuromorphic Computing and Optoelectronic Inte...\n",
            "256    Dark Matter of Intelligence and Self-Supervise...\n",
            "286    Reality is an Illusion – How Evolution Hid the...\n",
            "165    Deep Work, Focus, Productivity, Email, and Soc...\n",
            "268    Space Colonization and Self-Assembling Space M...\n",
            "137           Ayn Rand and the Philosophy of Objectivism\n",
            "162    Difficult Conversations, Freedom of Speech, an...\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 9: Comparar Resultados y Documentar\n"
      ],
      "metadata": {
        "id": "i_jNYMThjeXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis y comparación de resultados\n",
        "# Esta celda está destinada a documentar las observaciones sobre las fortalezas y debilidades de cada método basado en los resultados de recuperación\n",
        "\n",
        "def compare_results(query, tfidf_matrix, bert_embeddings, dataset):\n",
        "    tfidf_results, bert_results = procesar_consulta(query, tfidf_matrix, bert_embeddings, dataset)\n",
        "\n",
        "    print(\"Comparación de Resultados para la consulta:\", query)\n",
        "    print(\"\\nResultados de TF-IDF:\")\n",
        "    print(tfidf_results.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "    print(\"\\nResultados de BERT:\")\n",
        "    print(bert_results.head(10))  # Mostrar los 10 mejores resultados\n",
        "\n",
        "    # Documentar observaciones\n",
        "    print(\"\\nObservaciones:\")\n",
        "    print(\"TF-IDF:\")\n",
        "    print(\"- Ventajas: Rápido de calcular, adecuado para términos frecuentes.\")\n",
        "    print(\"- Desventajas: Puede no capturar bien el contexto semántico.\")\n",
        "\n",
        "    print(\"BERT:\")\n",
        "    print(\"- Ventajas: Captura el contexto semántico, puede manejar variaciones en el lenguaje.\")\n",
        "    print(\"- Desventajas: Más lento de calcular, requiere más recursos computacionales.\")\n",
        "\n",
        "# Probar la comparación con una consulta de ejemplo\n",
        "compare_results(\"Artificial Intelligence\", tfidf_matrix, bert_embeddings, dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-uw9yt0l8mL",
        "outputId": "624d2d2d-9477-4845-bbc3-fa9baed791b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de Resultados para la consulta: Artificial Intelligence\n",
            "\n",
            "Resultados de TF-IDF:\n",
            "2                                AI in the Age of Reason\n",
            "61      Concepts, Analogies, Common Sense & Future of AI\n",
            "119                             Measures of Intelligence\n",
            "38          Keras, Deep Learning, and the Progress of AI\n",
            "295    IQ Tests, Human Intelligence, and Group Differ...\n",
            "12                           Brains, Minds, and Machines\n",
            "0                                               Life 3.0\n",
            "91     Square, Cryptocurrency, and Artificial Intelli...\n",
            "1                                          Consciousness\n",
            "75      Universal Artificial Intelligence, AIXI, and AGI\n",
            "Name: title, dtype: object\n",
            "\n",
            "Resultados de BERT:\n",
            "296                   Marxism, Capitalism, and Economics\n",
            "168           Solving Martial Arts from First Principles\n",
            "3                                          Deep Learning\n",
            "223    Neuromorphic Computing and Optoelectronic Inte...\n",
            "256    Dark Matter of Intelligence and Self-Supervise...\n",
            "286    Reality is an Illusion – How Evolution Hid the...\n",
            "165    Deep Work, Focus, Productivity, Email, and Soc...\n",
            "268    Space Colonization and Self-Assembling Space M...\n",
            "137           Ayn Rand and the Philosophy of Objectivism\n",
            "162    Difficult Conversations, Freedom of Speech, an...\n",
            "Name: title, dtype: object\n",
            "\n",
            "Observaciones:\n",
            "TF-IDF:\n",
            "- Ventajas: Rápido de calcular, adecuado para términos frecuentes.\n",
            "- Desventajas: Puede no capturar bien el contexto semántico.\n",
            "BERT:\n",
            "- Ventajas: Captura el contexto semántico, puede manejar variaciones en el lenguaje.\n",
            "- Desventajas: Más lento de calcular, requiere más recursos computacionales.\n"
          ]
        }
      ]
    }
  ]
}